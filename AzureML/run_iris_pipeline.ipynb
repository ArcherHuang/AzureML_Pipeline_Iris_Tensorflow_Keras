{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# 安裝套件與確認 SDK 版本"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1679650312497
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Azure ML SDK Version:  1.48.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import azureml.core\n",
        "from azureml.core import (\n",
        "    Workspace,\n",
        "    Experiment,\n",
        "    Dataset,\n",
        "    Datastore,\n",
        "    ComputeTarget,\n",
        "    Environment,\n",
        "    ScriptRunConfig\n",
        ")\n",
        "from azureml.data import OutputFileDatasetConfig\n",
        "from azureml.core.compute import AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "from azureml.pipeline.steps import PythonScriptStep\n",
        "from azureml.pipeline.core import Pipeline\n",
        "from azureml.core.runconfig import RunConfiguration\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "from azureml.pipeline.core import PublishedPipeline\n",
        "from azureml.pipeline.core import PipelineData\n",
        "\n",
        "# check core SDK version number\n",
        "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# 配置工作環境"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1679650317837
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "workspace = Workspace.from_config()\n",
        "print(f\"workspace: {workspace}\")\n",
        "\n",
        "exp = Experiment(workspace=workspace, name=\"iris-fashion\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# 連接已有的 Blob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1679650322457
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import Datastore\n",
        "blob_datastore_name = 'iris'\n",
        "blob_account_name= ''\n",
        "blob_account_key = ''\n",
        "blob_container_name = ''\n",
        "blob_datastore = Datastore.register_azure_blob_container(workspace=workspace, \n",
        "                                                         datastore_name=blob_datastore_name, \n",
        "                                                         container_name=blob_container_name, \n",
        "                                                         account_name=blob_account_name,\n",
        "                                                         account_key=blob_account_key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# 建立運算叢集"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1679650338720
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating a new compute target...\n",
            "InProgress..\n",
            "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
            "Succeeded\n",
            "AmlCompute wait for completion finished\n",
            "\n",
            "Minimum number of nodes requested have been provisioned\n"
          ]
        }
      ],
      "source": [
        "cluster_name = \"cpu-cluster-4core\"\n",
        "\n",
        "found = False\n",
        "\n",
        "cts = workspace.compute_targets\n",
        "if cluster_name in cts and cts[cluster_name].type == \"AmlCompute\":\n",
        "    found = True\n",
        "    print(\"Found existing compute target.\")\n",
        "    compute_target = cts[cluster_name]\n",
        "if not found:\n",
        "    print(\"Creating a new compute target...\")\n",
        "    compute_config = AmlCompute.provisioning_configuration(\n",
        "        vm_size= \"STANDARD_DS3_V2\",\n",
        "        max_nodes=1,\n",
        "    )\n",
        "    compute_target = ComputeTarget.create(workspace, cluster_name, compute_config)\n",
        "    compute_target.wait_for_completion(\n",
        "        show_output=True, min_node_count=None, timeout_in_minutes=10\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# 設定執行環境的 config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1679650343009
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'enabled' is deprecated. Please use the azureml.core.runconfig.DockerConfiguration object with the 'use_docker' param instead.\n"
          ]
        }
      ],
      "source": [
        "run_config = RunConfiguration()\n",
        "run_config.environment.docker.enabled = True\n",
        "conda = CondaDependencies()\n",
        "conda.add_pip_package('azureml-sdk[automl]')\n",
        "conda.add_pip_package('opencv-python-headless')\n",
        "conda.add_pip_package('tensorflow')\n",
        "run_config.environment.python.conda_dependencies = conda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# 建立 Python 腳本步驟"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "gather": {
          "logged": 1679656756426
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pipeline is built\n",
            "Step Training Step is ready to be created [9d22a305]Step Evaluate Step is ready to be created [34809451]\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from azureml.pipeline.core import PipelineParameter\n",
        "from azureml.data.datapath import DataPath, DataPathComputeBinding\n",
        "from azureml.data.data_reference import DataReference\n",
        "from azureml.core import Dataset\n",
        "\n",
        "datastore = workspace.get_default_datastore()\n",
        "training_step_processed_data = PipelineData('training_step_processed_data', datastore=datastore)\n",
        "evaluate_step_processed_data = PipelineData('evaluate_step_processed_data', datastore=datastore)\n",
        "\n",
        "# 建立 OutputFileDatasetConfig，以傳遞資料\n",
        "prepared_data = OutputFileDatasetConfig('prepared_data')\n",
        "\n",
        "# Get Iris Datastore\n",
        "source_datastore = Datastore.get(workspace, 'iris')\n",
        "\n",
        "datasets = Dataset.get_all(workspace)\n",
        "if not 'IrisTrainingFileData' in datasets:\n",
        "    # Register training Dataset\n",
        "    iris_training_datastore_path = [DataPath(source_datastore, 'training/*')]\n",
        "    iris_training_ds = Dataset.File.from_files(path=iris_training_datastore_path)\n",
        "    iris_training_ds.register(workspace, \"IrisTrainingFileData\", create_new_version=True)\n",
        "\n",
        "if not 'IrisTestFileData' in datasets:\n",
        "    # Register training Dataset\n",
        "    iris_test_datastore_path = [DataPath(source_datastore, 'test/*')]\n",
        "    iris_test_ds = Dataset.File.from_files(path=iris_test_datastore_path)\n",
        "    iris_test_ds.register(workspace, \"IrisTestFileData\", create_new_version=True)\n",
        "\n",
        "fileIrisTrainingData = Dataset.get_by_name(workspace, 'IrisTrainingFileData')\n",
        "fileIrisTestData = Dataset.get_by_name(workspace, 'IrisTestFileData')\n",
        "\n",
        "script_folder = \"./pipeline-python\"\n",
        "dataset_training_path = \"/tmp/dataset/iris/training\"\n",
        "dataset_test_path = \"/tmp/dataset/iris/test\"\n",
        "\n",
        "training = PythonScriptStep(\n",
        "    name=\"Training Step\",\n",
        "    script_name=\"training.py\",\n",
        "    arguments=[\n",
        "        \"--blob_datastore_name\", blob_datastore_name,\n",
        "        \"--blob_account_name\", blob_account_name,\n",
        "        \"--blob_account_key\", blob_account_key,\n",
        "        \"--blob_container_name\", blob_container_name,\n",
        "        \"--output_path\", training_step_processed_data,\n",
        "        \"--dataset_training_path\", dataset_training_path,\n",
        "        \"--dataset_test_path\", dataset_test_path,\n",
        "        \"--output_folder\", prepared_data,\n",
        "    ],\n",
        "    inputs=[fileIrisTrainingData.as_named_input(\"Iris_Training_Files_mount\").as_mount(dataset_training_path),\n",
        "        fileIrisTestData.as_named_input(\"Iris_Test_Files_mount\").as_mount(dataset_test_path)],\n",
        "    outputs=[training_step_processed_data],\n",
        "    source_directory=script_folder,\n",
        "    compute_target=compute_target,\n",
        "    runconfig=run_config,\n",
        "    allow_reuse=False,\n",
        ")\n",
        "\n",
        "evaluate = PythonScriptStep(\n",
        "    name=\"Evaluate Step\",\n",
        "    script_name=\"evaluate.py\",\n",
        "    arguments=[\n",
        "        \"--output_path\", evaluate_step_processed_data,\n",
        "        \"--output_folder\", prepared_data.as_input(),\n",
        "    ],\n",
        "    inputs=[fileIrisTestData.as_named_input(\"Iris_Test_Files_mount\").as_mount(dataset_test_path)],\n",
        "    outputs=[evaluate_step_processed_data],\n",
        "    source_directory=script_folder,\n",
        "    compute_target=compute_target,\n",
        "    runconfig=run_config,\n",
        "    allow_reuse=False,\n",
        ")\n",
        "\n",
        "pipeline = Pipeline(workspace, steps=[training, evaluate])\n",
        "\n",
        "\n",
        "print(\"Pipeline is built\")\n",
        "pipeline.validate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# 部署成 pipeline 與儲存 pipeline ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "gather": {
          "logged": 1679641280504
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created step go step1 [ad5e7d43][4294c800-3945-4749-82d5-75bdfb5523bb], (This step will run and generate new outputs)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "36"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "published_pipeline = pipeline.publish(name=\"iris-blob-trigger-pipeline\", description=\"iris-blob-trigger-pipeline\", continue_on_step_failure=True)\n",
        "open('pipeline.id', 'w').write(published_pipeline.id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# 提交實驗"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "gather": {
          "logged": 1679656764888
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created step Training Step [9d22a305][2555685e-521e-479d-839d-76c37c4dd3b9], (This step will run and generate new outputs)Created step Evaluate Step [34809451][f7702132-7807-48e8-868e-8178f3dd02d3], (This step will run and generate new outputs)\n",
            "\n",
            "Submitted PipelineRun 38abaf63-b5cd-4fdf-a4fa-445d432e2648\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/38abaf63-b5cd-4fdf-a4fa-445d432e2648?wsid=/subscriptions/095c17da-056e-43f2-8d52-a30d1bdb6423/resourcegroups/adt-3d/workspaces/adt-3d&tid=c7f98dc5-2792-4fd7-bb88-7cb2506df48b\n"
          ]
        }
      ],
      "source": [
        "run = exp.submit(pipeline, regenerate_outputs=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# List Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "gather": {
          "logged": 1679656961045
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model name: tf-iris-decision-tree, version: 26\n"
          ]
        }
      ],
      "source": [
        "from azureml.core import Model\n",
        "for model in Model.list(workspace):\n",
        "    print(f\"model name: {model.name}, version: {model.version}\")"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
